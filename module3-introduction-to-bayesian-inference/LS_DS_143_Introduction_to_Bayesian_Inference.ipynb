{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS DS 143 Introduction to Bayesian Inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrittonWinterrose/DS-Unit-1-Sprint-4-Statistical-Tests-and-Experiments/blob/master/module3-introduction-to-bayesian-inference/LS_DS_143_Introduction_to_Bayesian_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science Module 143\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "!['Detector! What would the Bayesian statistician say if I asked him whether the--' [roll] 'I AM A NEUTRINO DETECTOR, NOT A LABYRINTH GUARD. SERIOUSLY, DID YOUR BRAIN FALL OUT?' [roll] '... yes.'](https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png)\n",
        "\n",
        "*[XKCD 1132](https://www.xkcd.com/1132/)*\n"
      ]
    },
    {
      "metadata": {
        "id": "3mz8p08BsN6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare - Bayes' Theorem and the Bayesian mindset"
      ]
    },
    {
      "metadata": {
        "id": "GhycNr-Sbeie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bayes' theorem possesses a near-mythical quality - a bit of math that somehow magically evaluates a situation. But this mythicalness has more to do with its reputation and advanced applications than the actual core of it - deriving it is actually remarkably straightforward.\n",
        "\n",
        "### The Law of Total Probability\n",
        "\n",
        "By definition, the total probability of all outcomes (events) if some variable (event space) $A$ is 1. That is:\n",
        "\n",
        "$$P(A) = \\sum_n P(A_n) = 1$$\n",
        "\n",
        "The law of total probability takes this further, considering two variables ($A$ and $B$) and relating their marginal probabilities (their likelihoods considered independently, without reference to one another) and their conditional probabilities (their likelihoods considered jointly). A marginal probability is simply notated as e.g. $P(A)$, while a conditional probability is notated $P(A|B)$, which reads \"probability of $A$ *given* $B$\".\n",
        "\n",
        "The law of total probability states:\n",
        "\n",
        "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
        "\n",
        "In words - the total probability of $A$ is equal to the sum of the conditional probability of $A$ on any given event $B_n$ times the probability of that event $B_n$, and summed over all possible events in $B$.\n",
        "\n",
        "### The Law of Conditional Probability\n",
        "\n",
        "What's the probability of something conditioned on something else? To determine this we have to go back to set theory and think about the intersection of sets:\n",
        "\n",
        "The formula for actual calculation:\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
        "\n",
        "We can see how this relates back to the law of total probability - multiply both sides by $P(B)$ and you get $P(A|B)P(B) = P(A \\cap B)$ - replaced back into the law of total probability we get $P(A) = \\sum_n P(A \\cap B_n)$.\n",
        "\n",
        "This may not seem like an improvement at first, but try to relate it back to the above picture - if you think of sets as physical objects, we're saying that the total probability of $A$ given $B$ is all the little pieces of it intersected with $B$, added together. The conditional probability is then just that again, but divided by the probability of $B$ itself happening in the first place.\n",
        "\n",
        "### Bayes Theorem\n",
        "\n",
        "Here is is, the seemingly magic tool:\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
        "\n",
        "In words - the probability of $A$ conditioned on $B$ is the probability of $B$ conditioned on $A$, times the probability of $A$ and divided by the probability of $B$. These unconditioned probabilities are referred to as \"prior beliefs\", and the conditioned probabilities as \"updated.\"\n",
        "\n",
        "Why is this important? Scroll back up to the XKCD example - the Bayesian statistician draws a less absurd conclusion because their prior belief in the likelihood that the sun will go nova is extremely low. So, even when updated based on evidence from a detector that is $35/36 = 0.972$ accurate, the prior belief doesn't shift enough to change their overall opinion.\n",
        "\n",
        "There's many examples of Bayes' theorem - one less absurd example is to apply to [breathalyzer tests](https://www.bayestheorem.net/breathalyzer-example/). You may think that a breathalyzer test that is 100% accurate for true positives (detecting somebody who is drunk) is pretty good, but what if it also has 8% false positives (indicating somebody is drunk when they're not)? And furthermore, the rate of drunk driving (and thus our prior belief)  is 1/1000.\n",
        "\n",
        "What is the likelihood somebody really is drunk if they test positive? Some may guess it's 92% - the difference between the true positives and the false positives. But we have a prior belief of the background/true rate of drunk driving. Sounds like a job for Bayes' theorem!\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(Drunk | Positive) &= \\frac{P(Positive | Drunk)P(Drunk)}{P(Positive)} \\\\\n",
        "&= \\frac{1 \\times 0.001}{0.08} \\\\\n",
        "&= 0.0125\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In other words, the likelihood that somebody is drunk given they tested positive with a breathalyzer in this situation is only 1.25% - probably much lower than you'd guess. This is why, in practice, it's important to have a repeated test to confirm (the probability of two false positives in a row is $0.08 * 0.08 = 0.0064$, much lower), and Bayes' theorem has been relevant in court cases where proper consideration of evidence was important."
      ]
    },
    {
      "metadata": {
        "id": "htI3DGvDsRJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Live Lecture - Deriving Bayes' Theorem, Calculating Bayesian Confidence"
      ]
    },
    {
      "metadata": {
        "id": "moIJNQ-nbfe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that $P(A|B)$ appears in the above laws - in Bayesian terms, this is the belief in $A$ updated for the evidence $B$. So all we need to do is solve for this term to derive Bayes' theorem. Let's do it together!\n",
        "\n",
        "$x = 2$ is an inline equation.\n",
        "\n",
        "$$\n",
        "x = 2\n",
        "$$\n",
        "\n",
        "is a block equation.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "x &= 2 \\\\\n",
        "&= 1 + 1\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now let's derive Bayes!\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(A \\cap B) &= P(B \\cap A) \\\\\n",
        "\\\\\n",
        "P(A|B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n",
        "\\Rightarrow P(A|B)P(B) &= P(A \\cap B) \\\\\n",
        "P(B|A) &= \\frac{P(B \\cap A)}{P(A)} \\\\\n",
        "\\Rightarrow P(B|A)P(A) &= P(B \\cap A) = P(A \\cap B) \\\\\n",
        "\\Rightarrow P(A|B)P(B) &= P(B|A)P(A) \\\\\n",
        "\\Rightarrow P(A|B)&= \\frac{P(B|A)P(A)}{P(B)}\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "ke-5EqJI0Tsn",
        "colab_type": "code",
        "outputId": "f61e2cfc-8df3-4f29-e481-21fcdf3802a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Activity 2 - Use SciPy to calculate Bayesian confidence intervals\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html#scipy.stats.bayes_mvs\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "coinflips = np.random.binomial(n=1, p=0.5, size=100)\n",
        "print(coinflips)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jL7qqrafmMEY",
        "colab_type": "code",
        "outputId": "a1c7d103-4eb9-401c-a315-59f295247a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Frequentist approach (from yesterday)\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "  \"\"\"\n",
        "  Calculate a confidence interval around a sample mean for given data.\n",
        "  Using t-distribution and two-tailed test, default 95% confidence. \n",
        "  \n",
        "  Arguments:\n",
        "    data - iterable (list or numpy array) of sample observations\n",
        "    confidence - level of confidence for the interval\n",
        "  \n",
        "  Returns:\n",
        "    tuple of (mean, lower bound, upper bound)\n",
        "  \"\"\"\n",
        "  data = np.array(data)\n",
        "  mean = np.mean(data)\n",
        "  n = len(data)\n",
        "  stderr = stats.sem(data)\n",
        "  interval = stderr * stats.t.ppf((1 + confidence) / 2., n - 1)\n",
        "  return (mean, mean - interval, mean + interval)\n",
        "\n",
        "confidence_interval(coinflips)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.47, 0.3704689875017368, 0.5695310124982632)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "TsUDVTHQnMR_",
        "colab_type": "code",
        "outputId": "9d4fe4c6-8dd1-4d53-f23f-d3b17ca616ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(coinflips).describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.501614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0\n",
              "count  100.000000\n",
              "mean     0.470000\n",
              "std      0.501614\n",
              "min      0.000000\n",
              "25%      0.000000\n",
              "50%      0.000000\n",
              "75%      1.000000\n",
              "max      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "VR5B9HHSmchp",
        "colab_type": "code",
        "outputId": "bd0f874c-15dc-4bfc-ceb8-bc4346a8e551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "stats.bayes_mvs(coinflips)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.47, minmax=(0.38671252844915566, 0.5532874715508442)),\n",
              " Variance(statistic=0.25680412371134015, minmax=(0.20215017434095597, 0.323311952657888)),\n",
              " Std_dev(statistic=0.5054540733507159, minmax=(0.4496111368070813, 0.5686052696360525)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "Vlqae8ZqmqBh",
        "colab_type": "code",
        "outputId": "7e8cfe65-b8f3-45c5-b028-de900d3fdcd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's do something else medical\n",
        "import random\n",
        "\n",
        "# We have two groups of people, one treated one non-treated\n",
        "# Treated people recover with probability 0.65\n",
        "# Non-treated people recover with probability 0.4\n",
        "treatment_group = np.random.binomial(n=1, p=0.65, size=40)\n",
        "nontreated_group = np.random.binomial(n=1, p=0.4, size=40)\n",
        "\n",
        "print(treatment_group)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHnC227wq6WA",
        "colab_type": "code",
        "outputId": "7eb311b8-7aba-48c1-cc5b-a6e3bab95c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'treated': treatment_group,\n",
        "                   'untreated': nontreated_group})\n",
        "df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>treated</th>\n",
              "      <th>untreated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.483046</td>\n",
              "      <td>0.483046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         treated  untreated\n",
              "count  40.000000  40.000000\n",
              "mean    0.650000   0.350000\n",
              "std     0.483046   0.483046\n",
              "min     0.000000   0.000000\n",
              "25%     0.000000   0.000000\n",
              "50%     1.000000   0.000000\n",
              "75%     1.000000   1.000000\n",
              "max     1.000000   1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "r2BImsQhrJcG",
        "colab_type": "code",
        "outputId": "772a622b-6d36-46a7-e78f-7f254abbf0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>treated</th>\n",
              "      <th>untreated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   treated  untreated\n",
              "0        1          1\n",
              "1        0          0\n",
              "2        1          1\n",
              "3        0          0\n",
              "4        1          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "GWOO804dr9Dj",
        "colab_type": "code",
        "outputId": "02d77394-7376-4dfa-dc5f-ec00c07d85d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Frequentist hypothesis test\n",
        "from scipy import stats\n",
        "stats.ttest_ind(df.treated, df.untreated)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=2.7774602993176547, pvalue=0.006858718177813595)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "TTlkpwAht6_x",
        "colab_type": "code",
        "outputId": "6b819c80-0458-4b94-90f5-b3835e8d59fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "stats.bayes_mvs(df.treated)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.65, minmax=(0.5213155371392566, 0.7786844628607433)),\n",
              " Variance(statistic=0.245945945945946, minmax=(0.16675148465986808, 0.3541491239670207)),\n",
              " Std_dev(statistic=0.4925902017165105, minmax=(0.4083521576530092, 0.5951042967136271)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "b1T_lU1auPQq",
        "colab_type": "code",
        "outputId": "15114dc5-c953-4c8e-801d-1318107843cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "stats.bayes_mvs(df.untreated)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.35, minmax=(0.2213155371392566, 0.4786844628607433)),\n",
              " Variance(statistic=0.24594594594594596, minmax=(0.16675148465986805, 0.35414912396702064)),\n",
              " Std_dev(statistic=0.4925902017165105, minmax=(0.4083521576530092, 0.5951042967136271)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "sLWQbmscuvdk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Suggested task - write your own Bayes test function\n",
        "# that compares CIs from stats.bayes_mvs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Assignment - Code it up!\n",
        "\n",
        "Most of the above was pure math - write Python code to reproduce the results. This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up, and as a stretch goal - refactor your code into helpful reusable functions!\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/) - you could and should create something similar!\n",
        "\n",
        "Stretch goal - apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective."
      ]
    },
    {
      "metadata": {
        "id": "Cr66mO2Exkyk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Yesterday (importing the med dataset)"
      ]
    },
    {
      "metadata": {
        "id": "uIvmyg1exKpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "39245472-6707-4fdc-d61e-e81c789c36fd"
      },
      "cell_type": "code",
      "source": [
        "# Getting started with drug data\n",
        "# http://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29\n",
        "\n",
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-05 23:50:53--  http://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/zip]\n",
            "Saving to: ‘drugsCom_raw.zip.1’\n",
            "\n",
            "drugsCom_raw.zip.1  100%[===================>]  41.00M  18.2MB/s    in 2.3s    \n",
            "\n",
            "2018-12-05 23:50:56 (18.2 MB/s) - ‘drugsCom_raw.zip.1’ saved [42989872/42989872]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jyGQP3Y9xKjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "533bf7df-c62f-45fe-dc59-0eab69441e8a"
      },
      "cell_type": "code",
      "source": [
        "!unzip drugsCom_raw.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drugsCom_raw.zip\n",
            "replace drugsComTest_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace drugsComTrain_raw.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IflVC3-ZxKbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "65ec73d8-921e-49f7-848f-46ff32ca3a0f"
      },
      "cell_type": "code",
      "source": [
        "!head drugsComTrain_raw.tsv"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tdrugName\tcondition\treview\trating\tdate\tusefulCount\r\n",
            "206461\tValsartan\tLeft Ventricular Dysfunction\t\"\"\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"\"\"\t9.0\tMay 20, 2012\t27\r\n",
            "95260\tGuanfacine\tADHD\t\"\"\"My son is halfway through his fourth week of Intuniv. We became concerned when he began this last week, when he started taking the highest dose he will be on. For two days, he could hardly get out of bed, was very cranky, and slept for nearly 8 hours on a drive home from school vacation (very unusual for him.) I called his doctor on Monday morning and she said to stick it out a few days. See how he did at school, and with getting up in the morning. The last two days have been problem free. He is MUCH more agreeable than ever. He is less emotional (a good thing), less cranky. He is remembering all the things he should. Overall his behavior is better. \r\n",
            "We have tried many different medications and so far this is the most effective.\"\"\"\t8.0\tApril 27, 2010\t192\r\n",
            "92703\tLybrel\tBirth Control\t\"\"\"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects. But it contained hormone gestodene, which is not available in US, so I switched to Lybrel, because the ingredients are similar. When my other pills ended, I started Lybrel immediately, on my first day of period, as the instructions said. And the period lasted for two weeks. When taking the second pack- same two weeks. And now, with third pack things got even worse- my third period lasted for two weeks and now it&#039;s the end of the third week- I still have daily brown discharge.\r\n",
            "The positive side is that I didn&#039;t have any other side effects. The idea of being period free was so tempting... Alas.\"\"\"\t5.0\tDecember 14, 2009\t17\r\n",
            "138000\tOrtho Evra\tBirth Control\t\"\"\"This is my first time using any form of birth control. I&#039;m glad I went with the patch, I have been on it for 8 months. At first It decreased my libido but that subsided. The only downside is that it made my periods longer (5-6 days to be exact) I used to only have periods for 3-4 days max also made my cramps intense for the first two days of my period, I never had cramps before using birth control. Other than that in happy with the patch\"\"\"\t8.0\tNovember 3, 2015\t10\r\n",
            "35696\tBuprenorphine / naloxone\tOpiate Dependence\t\"\"\"Suboxone has completely turned my life around.  I feel healthier, I&#039;m excelling at my job and I always have money in my pocket and my savings account.  I had none of those before Suboxone and spent years abusing oxycontin.  My paycheck was already spent by the time I got it and I started resorting to scheming and stealing to fund my addiction.  All that is history.  If you&#039;re ready to stop, there&#039;s a good chance that suboxone will put you on the path of great life again.  I have found the side-effects to be minimal compared to oxycontin.  I&#039;m actually sleeping better.   Slight constipation is about it for me.  It truly is amazing. The cost pales in comparison to what I spent on oxycontin.\"\"\"\t9.0\tNovember 27, 2016\t37\r\n",
            "155963\tCialis\tBenign Prostatic Hyperplasia\t\"\"\"2nd day on 5mg started to work with rock hard erections however experianced headache, lower bowel preassure. 3rd day erections would wake me up &amp; hurt! Leg/ankles aches   severe lower bowel preassure like you need to go #2 but can&#039;t! Enjoyed the initial rockhard erections but not at these side effects or $230 for months supply! I&#039;m 50 &amp; work out 3Xs a week. Not worth side effects!\"\"\"\t2.0\tNovember 28, 2015\t43\r\n",
            "165907\tLevonorgestrel\tEmergency Contraception\t\"\"\"He pulled out, but he cummed a bit in me. I took the Plan B 26 hours later, and took a pregnancy test two weeks later - - I&#039;m pregnant.\"\"\"\t1.0\tMarch 7, 2017\t5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IFx0NubCxKRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1cae0e63-dee0-4e39-b51a-65299d95335a"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_table('drugsComTrain_raw.tsv')\n",
        "df.head()\n",
        "\n",
        "### FROM YESTERDAY \n",
        "\"\"\"\n",
        "I want to take the df, filter by condition, drug, confidence interval, sample size cutoff)\n",
        "Then loop through all the drugs for a specific condition and calculate their\n",
        "mean, top limit, and bottom limit. \n",
        "\"\"\"\n",
        "# Create Confidence Interval Function\n",
        "def confidence_interval (data, ci_percent):\n",
        "  data = np.array(data) # Makes sure our data is in a numpy array\n",
        "  mean = np.mean(data)\n",
        "  n = len(data)\n",
        "  stderr = stats.sem(data)\n",
        "  interval = stderr * stats.t.ppf((1 + ci_percent) / 2., n - 1)\n",
        "  return (mean, mean - interval, mean + interval)\n",
        "\n",
        "\n",
        "def condition_compare (df, condition_id, ci_percent, sample_size_cutoff):\n",
        "  output_names = [\"Drug Name\", \"Sample Mean\", \"Lower Bound\", \"Upper Bound\", \"Sample Size\"]\n",
        "  drug_compare = []\n",
        "  data = df[df.condition == condition_id]\n",
        "  for drug in data.drugName.unique():\n",
        "    one_drug = data[data.drugName == drug].rating\n",
        "    if one_drug.size > sample_size_cutoff:\n",
        "#\n",
        "      mean, ilower, iupper= confidence_interval(one_drug, ci_percent)\n",
        "      entry = [drug, mean, ilower, iupper, one_drug.size]\n",
        "      drug_compare.append(entry)\n",
        "  return pd.DataFrame(drug_compare, columns=output_names)\n",
        "\n",
        "\n",
        "df2 = condition_compare(df, \"Depression\", 0.95, 10).sort_values(by=\"Sample Mean\", ascending=False)\n",
        "df2.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Drug Name</th>\n",
              "      <th>Sample Mean</th>\n",
              "      <th>Lower Bound</th>\n",
              "      <th>Upper Bound</th>\n",
              "      <th>Sample Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Niacin</td>\n",
              "      <td>9.857143</td>\n",
              "      <td>9.647474</td>\n",
              "      <td>10.066812</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Tramadol</td>\n",
              "      <td>9.288462</td>\n",
              "      <td>8.934000</td>\n",
              "      <td>9.642923</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Clomipramine</td>\n",
              "      <td>9.181818</td>\n",
              "      <td>8.106160</td>\n",
              "      <td>10.257476</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Xanax</td>\n",
              "      <td>9.166667</td>\n",
              "      <td>8.603654</td>\n",
              "      <td>9.729679</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Methylphenidate</td>\n",
              "      <td>9.160000</td>\n",
              "      <td>8.789263</td>\n",
              "      <td>9.530737</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Drug Name  Sample Mean  Lower Bound  Upper Bound  Sample Size\n",
              "62           Niacin     9.857143     9.647474    10.066812           14\n",
              "47         Tramadol     9.288462     8.934000     9.642923           52\n",
              "68     Clomipramine     9.181818     8.106160    10.257476           11\n",
              "37            Xanax     9.166667     8.603654     9.729679           42\n",
              "17  Methylphenidate     9.160000     8.789263     9.530737           25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "sjRWjVVLxgv8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some stuff\n"
      ]
    },
    {
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oUrpsNuCwl6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train = pd.read_table('drugsComTrain_raw.tsv')\n",
        "df_test = pd.read_table('drugsComTest_raw.tsv')\n",
        "\n",
        "df_main = pd.concat([df_train, df_test], axis=0)\n",
        "df_main"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FW7_GpErwo2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "ae844757-e3e8-4e67-8602-ae14c8f2e9dc"
      },
      "cell_type": "code",
      "source": [
        "# Clean up text\n",
        "pd.set_option('display.width', 1000)\n",
        "rx_pat = r\"(\\\\r)|(\\\\n)|(\\\\t)|(\\\\f)|(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(&#039;)|(\\\\)|(\\-)|(\\d\\s)|(\\d)|(\\s{2,})|(\\-)|(\\/)\"\n",
        "    \n",
        "df_main['review'].replace(regex=True,inplace=True,to_replace=rx_pat, value=r'')\n",
        "df_main.review"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        It has no side effect I take it in combination...\n",
              "1        My son is halfway through his fourth week of I...\n",
              "2        I used to take another oral contraceptive whic...\n",
              "3        This is my first time using any form of birth ...\n",
              "4        Suboxone has completely turned my life aroundI...\n",
              "5        nd day on mg started to work with rock hard er...\n",
              "6        He pulled out but he cummed a bit in me I took...\n",
              "7        Abilify changed my life There is hope I was on...\n",
              "8         I Ve hadnothing but problems with the Keppera...\n",
              "9        I had been on the pill for many years When my ...\n",
              "10       I have been on this medication almost two week...\n",
              "11       I have taken antidepressants for years with so...\n",
              "12       I had Crohns with a resection years ago and ha...\n",
              "13       Have a little bit of a lingering cough from a ...\n",
              "14       Started Nexplanon months ago because I have a ...\n",
              "15       I have been taking Saxenda since July I had se...\n",
              "16       This drug worked very well for me and cleared ...\n",
              "17       Ive been taking amitriptyline since January af...\n",
              "18       Ive been on every medicine under the sun it se...\n",
              "19       I have been on Tasigna for just over years now...\n",
              "20       Spring of I was hospitalized with pnuemonia an...\n",
              "21       I have insomnia its horrible My story begins w...\n",
              "22       Nexplanon does its job I can have worry free s...\n",
              "23       I live in Western Australia and disturbed by s...\n",
              "24       Do not use the cream that comes with this It t...\n",
              "25       Was prescribed one dose over the course of one...\n",
              "26       Im writing a second review on VaniqaI started ...\n",
              "27       Hi all My son who is was diagnosed when he was...\n",
              "28       Honestly I have been taking ativan for years n...\n",
              "29       At first I suffered through them This included...\n",
              "                               ...                        \n",
              "53736    Ativan works I just started getting panic atta...\n",
              "53737    Major sleepiness Used it in the morning and in...\n",
              "53738    Took antibiotics and got a yeast infection wen...\n",
              "53739    Ambien is a wonderful sleep aidFor people who ...\n",
              "53740    I had mild Barretts esophagus and was on Dexil...\n",
              "53741    I first would like to thank all of you that po...\n",
              "53742    Have been taking it for years milligrams no si...\n",
              "53743    Clarifoam EF is a wonderful productI have Rosa...\n",
              "53744    Woman of Cuban and Puerto Rican heritage and p...\n",
              "53745    Ive been on clomipramine years now and basical...\n",
              "53746    Ive had diarrhoea for days now with minimal sl...\n",
              "53747    Horrible I have been a smoker for yearsI tried...\n",
              "53748                      Glad to have it available to me\n",
              "53749    After years of opioid and heroin addiction I h...\n",
              "53750    I have had the worst experience with this pill...\n",
              "53751    I took chantix a little over a month It made m...\n",
              "53752    After first month of taking Epclusa I am undet...\n",
              "53753    Diagnosed with general anxiety disorderWould h...\n",
              "53754    It didnt help me at all I craved chocolate all...\n",
              "53755    I now suffer from excessive tiredness and lack...\n",
              "53756    Treatment for ADHD save my life Dont believe a...\n",
              "53757    This is my rd time taking this medicine First ...\n",
              "53758    This medicine kept me from sleeping the whole ...\n",
              "53759    I was on Microgestin for about years Over the ...\n",
              "53760    I started taking Apri about months ago My brea...\n",
              "53761    I have taken Tamoxifen for years Side effects ...\n",
              "53762    Ive been taking Lexapro escitaploprgram since ...\n",
              "53763    Im married years old and I have no kids Taking...\n",
              "53764    I was prescribed Nucynta for severe neckshould...\n",
              "53765                                             It works\n",
              "Name: review, Length: 215063, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "yJRKrphAwssF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Nailed it. \n",
        "df_main['review'] = df_train['review'].str.lower()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5I7YcWm4wuv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VECTORIZE IT (One Hot Encode It)\n",
        "# Each word becomes one feature (column)\n",
        "# This is probably where I'll get lost.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(df_train['review'])\n",
        "X = cv.transform(df_main['review'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPI5PWjiwxWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a222f15e-12c4-4f9c-a2f6-09b648e7f6d0"
      },
      "cell_type": "code",
      "source": [
        "X"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<215063x49899 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 12637415 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "cdX4mGwCwyu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f27118c1-0c8d-4b96-a7a8-4118aa9280b0"
      },
      "cell_type": "code",
      "source": [
        "np.size(X,0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215063"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "e0d289Mxwzll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "959c37cd-285f-4eb4-f55a-6d03121372d0"
      },
      "cell_type": "code",
      "source": [
        "# Make this split X into test and train. \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = [1 if i < np.size(X,0)*.5 else 0 for i in range(np.size(X,0))]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.5)\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "    \n",
        "# Accuracy for C=0.01: 0.9245629262244265\n",
        "# Accuracy for C=0.05: 0.9245629262244265\n",
        "# Accuracy for C=0.25: 0.9240917544947304\n",
        "# Accuracy for C=0.5: 0.9221574705517669\n",
        "# Accuracy for C=1: 0.9173713577185368"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.47604434028940223\n",
            "Accuracy for C=0.05: 0.46658669047353346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9d30fd8f800b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     print (\"Accuracy for C=%s: %s\" \n\u001b[1;32m     15\u001b[0m            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1235\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1Oab8BTFw39W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Still Broken\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.5)\n",
        "\n",
        "final_model = LogisticRegression(C=0.05)\n",
        "final_model.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_model.predict(X_test)))\n",
        "# Final Accuracy: 0.88128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGN2Lxnfw4wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        cv.get_feature_names(), final_model.coef_[0]\n",
        "    )\n",
        "}\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1], \n",
        "    reverse=True)[:5]:\n",
        "    print (best_positive)\n",
        "    \n",
        "#     ('excellent', 0.9288812418118644)\n",
        "#     ('perfect', 0.7934641227980576)\n",
        "#     ('great', 0.675040909917553)\n",
        "#     ('amazing', 0.6160398142631545)\n",
        "#     ('superb', 0.6063967799425831)\n",
        "    \n",
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1])[:5]:\n",
        "    print (best_negative)\n",
        "    \n",
        "#     ('worst', -1.367978497228895)\n",
        "#     ('waste', -1.1684451288279047)\n",
        "#     ('awful', -1.0277001734353677)\n",
        "#     ('poorly', -0.8748317895742782)\n",
        "#     ('boring', -0.8587249740682945)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}